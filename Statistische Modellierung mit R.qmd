---
title: "Statistische Modellierung mit R"
subtitle: "Ein Workshop für die PH Zürich"
date: 2025-10-17
format:
    html: 
      self-contained: true
      grid: 
        margin-width: 350px
    pdf: 
      pdf-engine: xelatex
brand:
  color:
    link: "#1bbc9d"
execute: 
  echo: fenced
lang: de
reference-location: margin
#citation-location: margin
bibliography: skeleton.bib
---

# Methodology: The Science before Statistics

Jede statistische Modellierung gewinnt an Aussagekraft, je umfassender sie die inhaltliche Fragestellung abzubilden im Stande ist. Um aus der riesigen Fülle an Optionen geeignet und zielgerichtet auswählen zu können sind die folgenden Unterscheidungen hilfreich.

## Erkenntnisinteressen

Ganz grundlegend kann a priori das Erkenntnisinteresse von Studien in die folgenden vier Kategorien unterschieden werden:

::: column-page-right
| Deskriptiv | Explorativ | Explanativ | Prädiktiv |
|------------------|------------------|------------------|------------------|
| populationsbeschreibend | hypothesengenerierend | hypothesenprüfend | Datenpunkte vorhersagend oder imputierend |
| *Bei welchem Anteil 15-Jähriger in Deutschland handelt es sich um funktionale Analphabet:innen?* | *Was sind potentielle Ursachen für genderbezogene Disparitäten im Analphabetismus?* | *Sind 15-jährige Jungen häufiger Analphabeten als 15-jährige Mädchen?* | *Mit welchen Variablen können Schüler:innen at risk erfolgreich identifiziert werden?* |

: Erkenntisinteressen nach [@doering2016].
:::

## Gütekriterien wiss. Erkenntnis nach @campbell1957

Für ein erfolgreiches Studiendesign und die anschließende statistische Analyse ist es sehr wertvoll sich vorab über Schwerpunkte besonders gewünschter Aspekte wissenschaftlicher Güte Gedanken zu machen. Insbesondere über die Unterkriterien **Methodischer Strenge**

-   **Konstruktvalidität** (*Inwiefern ist die Interpretation der Messwerte angemessen?*)
-   **Interne Validität** (*Inwiefern sind Assoziationen von unabhängiger \[beeinflussender\] und abhängiger \[beeinflusster\] Variabler als kausale Effekte interpretierbar?*)
-   **Externe Validität** (*Inwiefern können die Schlussfolgerungen der Studie verallgemeinert werden?*)
-   **Statistische Validität** (*Wie robust und angemessen sind die verwendeten statistischen Verfahren?*)

## Deskriptiv- und Inferenzstatistik

**Deskriptive Statistik** beschreibt vorliegende Daten (z.B. Effektstärken), während **Inferenzstatistik** Aussagen über den die Daten generierenden Mechanismus trifft. Beide können »eher einfach« oder »hoch komplex« sein und oftmals sethen sie in einem synergetischen Verhältnis (siehe @fig-jingjang).

::: column-margin
![Verhältnis von deskriptiver und Inferenzstatistik"](img/yingyang.svg){#fig-jingjang width=300px}
:::

## Bayesianisches und Frequentistisches Schätzen und Testen
Eine sehr heuristische Klassifikation inferenzstatistischer Verfahren stellt die Unterscheidung von statistischer Schätzung und Testung:

> (Inferenzstatistische) *Schätzungen* (estimation with quantified uncertainty) treffen anhand von Stichproben Aussagen über Parameter der Grundgesamtheit (Population) aus der die Stichprobe gezogen wurde.[^1]

[^1]: Bspw.: *Mit 96%er Wahrscheinlichkeit liegt die Analphabetismusinzidienz von 15-Jährigen in Deutschland zwischen .08 und .12* 

> (Inferenzstatistische) *Hypothesentests* bewerten anhand von Stichprobendaten die Gültigkeit von Hypothesen in der Grundgesamtheit (Population) aus der die Stichprobe gezogen wurde.[^2]

[^2]: Bspw.: *Nimmt man an, dass sich die Analphabetismusinzidienz von 15-Jährigen in Deutschland zwischen 2021 und 2025 nicht geändert hat beträgt die Wahrscheinlichkeit der vorliegenden Daten p = .032* 

Diese beiden Verfahren können sowohl im Rahmen der **frequentistischen Statistik** als auch der **bayesianischen Statistik** angewendet werden. Die folgende Tabelle gibt einen Überblick über die wichtigsten Werkzeuge:

|                        | Frequentistische Statistik | Bayesianische Statistik |
|------------------------|-----------------------------|--------------------------|
| Parameterschätzung     | Konfidenzintervalle         | Posterior Distributions  |
| Hypothesentest         | p-Werte                     | Bayes Faktoren & ROPE Procedure           |

## Hypothesenarten
Bayesianische wie frequentistischen Hypothesentests können unterschiedliche Arten von Hypothesen zugrunde gelegt werden:

* **Punkthypothesen** setzen Parameter gleich einer reellen Zahl; etwa $H_0\text{: } \delta = 0$ 
* **Äquivalenzhypothesen** nehmen Parameter in einem reellen Intervall an; etwa  $H_0\text{: } \delta \not\in\ [-.3, .3]$ 
* **Informative Hypothesen** nehmen eine Ordnungsrelation mehrerer Parameter an; etwa $\mu_{\text{Baseline}} < \mu_{\text{Imaginary Pill}} < \mu_{\text{Blinded Placebo}}$ [@buergler2023]

> **Die *Art* der (falsifizierten) Hypothese entscheidet wesentlich stärker über den Informationsgehalt eines Hypothesentests als die Entscheidung für das frequentistische oder bayesianische Paradigma** [@hoijtink2012].

Dies ist am leichtest anhand der Nullhypothese nachvollziehbar. Wird etwa die Nullhypothese $H_0\text{: } \delta = 0$ verworfen, wird entsprechend die Alternativhypothese $H_A\text{: } \delta \neq 0$ angenommen. Diese enthält aber quasi keine Information, da sie nur mit einer einzigen Beobachtung (d = 0.000000 ...) verworfen werden kann und im kritischen Rationalismus gilt, dass eine Aussage umso mehr Information enthält, umso leichter sie verworfen werden kann [@doering2016]. 

Äquivalenzhypothesen können sowohl frequentistisch [z.B. TOAST-Prozedur in R und JASP, @lakens2017] wie bayesianisch [z.B. ROPE-Ansatz @kruschke2015] getestet werden. Für das Testen informativer Hypothesen liegen bayesianische Methoden in (u.a.) JASP und R vor [z.B. `{bain}`, @gu2019] sowie in frequentistischen R-Paketen restriktor [@vanbrabant2020] und ic.infer [@gromping2010].

# Grundlagen der Regressionsanalyse
Regressionsanalysen sind ein sehr mächtiges Werkzeug um Zusammenhänge oder Unterschiede zwischen/in Variablen zu modellieren. Innerhalb der Regressionsanalyse kann sowohl geschätz als auch getestet werden und dies jeweils bayesianisch oder frequentistisch.

Die Grundidee der lineare Regression ist in [diesem interaktiven Applet](https://www.geogebra.org/m/wDpDdS7g) veranschaulicht.
Eine Abhängige Variable $y_i$ wird also als normalverteilt mit bedingtem Erwartungswert $b_0 + b_1*x_i$ und  $\sigma$ angenommen:

$$y_i \sim \mathcal{N}\left( b_0 + b_1*x_i, \sigma \right)$$


## Datengrundlage
Das wollen wir den berühmten Daten aus dem STAR-Experiment (Student/Teacher Achievement Ratio) illustrieren. In diesem Experiment wurden in Tennessee Schüler:innen zufällig auf Klassen mit kleiner (13-17 Schüler:innen pro Lehrer:in) und großer (22-25 Schüler:innen pro Lehrer:in) Klassengröße zugeteilt. Zusätzlich gab es Klassen großer Größe, die von einer:n ausgebildeten Hilfslehrer:in unterstützt wurde. Die Schüler:innen wurden über mehrere Jahre getestet.

Wir können die Daten 
```{r}
## Laden der Bibliotheken 
library(ggplot2)  # plots
library(dplyr)    # datawrangling
library(readr)    # data import
library(ggforce)  # sina plots


## Import der Daten ############################################################
data_star <- read_csv("data/star.csv")
# die Erklärung der Variablennamen kann mit `?mlmRev::star` aufgerufen werden

## Einfache lineare Regression #################################################

# Um nicht gleich mit Mehrebenenregression starten zu müssen, erstellen wir als
# erstes einen Subdatensatz, der nur eine:n Schüler:in pro Lehrer:in enthält

data_star_sub <- 
	data_star %>% 
	group_by(tch) %>% 
	sample_n(1) %>% 
	ungroup()

## »Effekt« der Klasse
ggplot(data_star_sub, aes(gr, math)) +
	geom_jitter() +
	#facet_wrap(~gr) +
	theme_minimal()

# Das Schuljahr K muss also zu 0 rekodiert werden

data_star_sub <- 
	data_star_sub %>% 
	mutate(grade = case_when(gr == "K" ~ 0,
													 gr == "1" ~ 1,
													 gr == "2" ~ 2,
													 gr == "3" ~ 3
													 ))

ggplot(data_star_sub, aes(grade, math)) +
	geom_jitter() +
	theme_minimal()

mod0 <- lm(math ~ grade, data = data_star_sub)
summary(mod0)
```
